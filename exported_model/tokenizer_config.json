{
  "model_max_length": 256,
  "tokenizer_class": "GPT2Tokenizer",
  "bos_token": "\u003C|endoftext|\u003E",
  "eos_token": "\u003C|endoftext|\u003E",
  "unk_token": "\u003C|endoftext|\u003E"
}